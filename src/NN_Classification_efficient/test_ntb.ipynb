{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "f5c82bd4cee0ed77a0aff302434c43771d96ea518805c934a760ccadbe76d687"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.nn_model import build_model\n",
    "from core.dataset import generate_dataset, generate_test_dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageFile\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "variables\n",
    "\"\"\"\n",
    "# not changable variables\n",
    "# fix bug\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "# path to TF2_OD_BRE\n",
    "main_dir_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath('test_ntb.ipynb'))))\n",
    "\n",
    "# path to DIPLOMKA\n",
    "diplomka_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath('test_ntb.ipynb'))))))\n",
    "# path to train folder\n",
    "train_folder_path = os.path.join(main_dir_path, r\"data\\\\Dataset_ready\\\\\")\n",
    "# input image size\n",
    "im_size = (224, 224)\n",
    "\n",
    "# labels for clases - dataset\n",
    "CLASS_NAMES = [\n",
    "        'Num: 0', 'Num: 1', 'Num: 2', 'Num: 3',\n",
    "        'Num: 4', 'Num: 5', 'Num: 6',\n",
    "        'Num: 7', 'Num: 8', 'Num: 9']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_w(model, PATH_TO_WEIGHS):\n",
    "    # The model weights (that are considered the best)\n",
    "    # are loaded into the model.\n",
    "    latest = tf.train.latest_checkpoint(PATH_TO_WEIGHS)\n",
    "    model.load_weights(latest)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Users\\marti\\Disk Google\\DIPLOMKA\\KODING\\TF2_OD_BRE\\results\\\\training_checkpoints\\\\colab_weigts_fine_tuning\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "variables\n",
    "\"\"\"\n",
    "NUM_CLASSES = 10\n",
    "IMG_SIZE = (224, 224)\n",
    "PATH_TO_WEIGHS = os.path.join(main_dir_path, r'results\\\\training_checkpoints\\\\colab_weigts_fine_tuning')\n",
    "\n",
    "print(PATH_TO_WEIGHS)\n",
    "# main dataset path\n",
    "PATH_TO_DATASET = os.path.join(main_dir_path, r'data\\\\Dataset_ready\\\\')\n",
    "PATH_TO_IMG = os.path.join(main_dir_path, r'data\\\\test\\\\camera\\\\')\n",
    "\n",
    "test_folder_path = os.path.join(\n",
    "    diplomka_path,\n",
    "    r'DATA\\DISPLAY_IMAGES\\images_classes_from_camera\\A1')\n",
    "\n",
    "\"\"\"\n",
    "MAIN CODE\n",
    "\"\"\"\n",
    "model_old = build_model(NUM_CLASSES)\n",
    "model = load_w(model_old, PATH_TO_WEIGHS)\n",
    "# camera_prediction(model, IMG_SIZE)\n",
    "# predict_img_folder(model, PATH_TO_IMG, image_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 15034 images belonging to 10 classes.\n",
      "[0 0 0 ... 9 9 9]\n",
      "new folder: 01_0\n",
      "new folder: 02_1\n",
      "new folder: 03_2\n",
      "new folder: 04_3\n",
      "new folder: 05_4\n",
      "new folder: 06_5\n",
      "new folder: 07_6\n",
      "new folder: 08_7\n",
      "new folder: 09_8\n",
      "new folder: 10_9\n",
      "Confusion Matrix\n",
      "[[1365   28    0    2    3    0    3    0    3    0]\n",
      " [  86 2731    1   71   59    0    5   50    0    0]\n",
      " [   7    3 2142  123    8   56    0    0    0    0]\n",
      " [  17    0    1 2249    6   13    0    6    0    0]\n",
      " [  20   16    0    6 1455   17    3    2    0    0]\n",
      " [   8    3  109   54   18 1556    3    0    0    0]\n",
      " [  11    4    1   47    1   33  885    1    0    0]\n",
      " [  27   44   23   40   58   12    0  550    0    0]\n",
      " [ 143    0    0    6    0   25   19    0  376   10]\n",
      " [  43    0    0    2    2  113    4    0   12  234]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    evaluate dataset and compute confusion matrix\n",
    "\"\"\"\n",
    "test_folder_path = \"C:\\\\Users\\\\marti\\\\OneDrive\\\\Plocha\\\\DP_OBRAZKY_DISPLAY\\\\display_classes_0-9_preprocessed\"\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "test_ds = generate_test_dataset(test_folder_path, image_size=IMG_SIZE)\n",
    "y_true = test_ds.classes  # numpy array of all labels\n",
    "print(y_true)\n",
    "\n",
    "# go trough all folders in the path\n",
    "for fo_number, folder in enumerate(sorted(os.listdir(test_folder_path))):\n",
    "    print(\"new folder:\", folder)\n",
    "    for fi_number, filename in enumerate(os.listdir(test_folder_path+'/'+folder)):\n",
    "        img_path = test_folder_path+'\\\\'+str(folder)+'\\\\'+str(filename)\n",
    "        img = keras.preprocessing.image.load_img(\n",
    "            img_path,\n",
    "            target_size=IMG_SIZE,\n",
    "            color_mode=\"rgb\",\n",
    "            grayscale=False\n",
    "        )\n",
    "\n",
    "        img_array = keras.preprocessing.image.img_to_array(img)\n",
    "        tf_img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "        predictions = model.predict(tf_img_array)\n",
    "        Y_pred = np.around(predictions)  # round prediction\n",
    "        Y_pred = Y_pred.argmax(axis=1)[0]\n",
    "        y_pred.append(Y_pred)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 787 images belonging to 10 classes.\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9]\n",
      "new folder: 0\n",
      "new folder: 1\n",
      "new folder: 2\n",
      "new folder: 3\n",
      "new folder: 4\n",
      "new folder: 5\n",
      "new folder: 6\n",
      "new folder: 7\n",
      "new folder: 8\n",
      "new folder: 9\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    evaluate dataset and compute confusion matrix\n",
    "\"\"\"\n",
    "test_folder_path = os.path.join(\n",
    "    diplomka_path,\n",
    "    r'DATA\\DISPLAY_IMAGES\\images_classes_from_camera\\A1')\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "test_ds = generate_test_dataset(test_folder_path, image_size=IMG_SIZE)\n",
    "y_true = test_ds.classes  # numpy array of all labels\n",
    "print(y_true)\n",
    "\n",
    "# go trough all folders in the path\n",
    "for fo_number, folder in enumerate(sorted(os.listdir(test_folder_path))):\n",
    "    print(\"new folder:\", folder)\n",
    "    for fi_number, filename in enumerate(os.listdir(test_folder_path+'/'+folder)):\n",
    "        img_path = test_folder_path+'\\\\'+str(folder)+'\\\\'+str(filename)\n",
    "        img = keras.preprocessing.image.load_img(\n",
    "            img_path,\n",
    "            target_size=IMG_SIZE,\n",
    "            color_mode=\"rgb\",\n",
    "            grayscale=False\n",
    "        )\n",
    "\n",
    "        img_array = keras.preprocessing.image.img_to_array(img)\n",
    "        tf_img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "        predictions = model.predict(tf_img_array)\n",
    "        Y_pred = np.around(predictions)  # round prediction\n",
    "        Y_pred = Y_pred.argmax(axis=1)[0]\n",
    "        y_pred.append(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n[[  0   0   0   0   0   0   0   0   0   0]\n [ 15  18   2   0  23   0   0   0   0   0]\n [  1   0  71   0   0   1   0   0   0   0]\n [ 13   0   0  31   0   0   1   3   0   0]\n [  1   0   0   0  54   1   0   0   0   0]\n [  2   0   0   0   0 117   0   0   0   0]\n [  0   0   0   0   1   2  86   0   0   0]\n [ 20  69   2   1  26   0   0  21   0   0]\n [  0   0   0   0   0   0  50   0  46   0]\n [ 16   0   0   2   8  67  16   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 3409 images belonging to 10 classes.\n",
      "[1 1 1 ... 7 7 9]\n",
      "new folder: 0\n",
      "new folder: 1\n",
      "new folder: 2\n",
      "new folder: 3\n",
      "new folder: 4\n",
      "new folder: 5\n",
      "new folder: 6\n",
      "new folder: 7\n",
      "new folder: 8\n",
      "new folder: 9\n",
      "Confusion Matrix\n",
      "[[  0   0   0   0   0   0   0   0   0]\n",
      " [ 20 464   0   0  30   0   1   4   0]\n",
      " [  0   0 718   0   0 159   0   0   0]\n",
      " [  0   0   0 321   0   0   0   0   0]\n",
      " [  0   0   0   0 373   4   0   0   0]\n",
      " [  0   0   0   0   0 440   0   0   0]\n",
      " [  0   0   0   0   0   3 559   0   0]\n",
      " [ 41  41   6   2   6   0   0 216   0]\n",
      " [  0   0   0   0   0   0   1   0   0]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    evaluate dataset and compute confusion matrix\n",
    "\"\"\"\n",
    "test_folder_path = os.path.join(\n",
    "    diplomka_path,\n",
    "    r'DATA\\DISPLAY_IMAGES\\images_classes_from_camera\\A3_01')\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "test_ds = generate_test_dataset(test_folder_path, image_size=IMG_SIZE)\n",
    "y_true = test_ds.classes  # numpy array of all labels\n",
    "print(y_true)\n",
    "\n",
    "# go trough all folders in the path\n",
    "for fo_number, folder in enumerate(sorted(os.listdir(test_folder_path))):\n",
    "    print(\"new folder:\", folder)\n",
    "    for fi_number, filename in enumerate(os.listdir(test_folder_path+'/'+folder)):\n",
    "        img_path = test_folder_path+'\\\\'+str(folder)+'\\\\'+str(filename)\n",
    "        img = keras.preprocessing.image.load_img(\n",
    "            img_path,\n",
    "            target_size=IMG_SIZE,\n",
    "            color_mode=\"rgb\",\n",
    "            grayscale=False\n",
    "        )\n",
    "\n",
    "        img_array = keras.preprocessing.image.img_to_array(img)\n",
    "        tf_img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "        predictions = model.predict(tf_img_array)\n",
    "        Y_pred = np.around(predictions)  # round prediction\n",
    "        Y_pred = Y_pred.argmax(axis=1)[0]\n",
    "        y_pred.append(Y_pred)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1776 images belonging to 10 classes.\n",
      "[1 1 1 ... 9 9 9]\n",
      "new folder: 0\n",
      "new folder: 1\n",
      "new folder: 2\n",
      "new folder: 3\n",
      "new folder: 4\n",
      "new folder: 5\n",
      "new folder: 6\n",
      "new folder: 7\n",
      "new folder: 8\n",
      "new folder: 9\n",
      "Confusion Matrix\n",
      "[[  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0  83   0   0  11   0   0   0   0   0]\n",
      " [  0   1 536   1   1  32   1   0   0   0]\n",
      " [  0   0   0 197   0   1   0   0   0   0]\n",
      " [  0   0   0   0 186   0   0   0   0   0]\n",
      " [  0   0   0   0   0 227   0   0   0   0]\n",
      " [  0   0   0   0   0  40 179   0   0   0]\n",
      " [  3   6   2   0   0   0   0 263   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0]\n",
      " [  0   0   0   0   0   5   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    evaluate dataset and compute confusion matrix\n",
    "\"\"\"\n",
    "test_folder_path = os.path.join(\n",
    "    diplomka_path,\n",
    "    r'DATA\\DISPLAY_IMAGES\\images_classes_from_camera\\A4')\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "test_ds = generate_test_dataset(test_folder_path, image_size=IMG_SIZE)\n",
    "y_true = test_ds.classes  # numpy array of all labels\n",
    "print(y_true)\n",
    "\n",
    "# go trough all folders in the path\n",
    "for fo_number, folder in enumerate(sorted(os.listdir(test_folder_path))):\n",
    "    print(\"new folder:\", folder)\n",
    "    for fi_number, filename in enumerate(os.listdir(test_folder_path+'/'+folder)):\n",
    "        img_path = test_folder_path+'\\\\'+str(folder)+'\\\\'+str(filename)\n",
    "        img = keras.preprocessing.image.load_img(\n",
    "            img_path,\n",
    "            target_size=IMG_SIZE,\n",
    "            color_mode=\"rgb\",\n",
    "            grayscale=False\n",
    "        )\n",
    "\n",
    "        img_array = keras.preprocessing.image.img_to_array(img)\n",
    "        tf_img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "        predictions = model.predict(tf_img_array)\n",
    "        Y_pred = np.around(predictions)  # round prediction\n",
    "        Y_pred = Y_pred.argmax(axis=1)[0]\n",
    "        y_pred.append(Y_pred)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1366 images belonging to 10 classes.\n",
      "[0 0 0 ... 7 8 9]\n",
      "new folder: 0\n",
      "new folder: 1\n",
      "new folder: 2\n",
      "new folder: 3\n",
      "new folder: 4\n",
      "new folder: 5\n",
      "new folder: 6\n",
      "new folder: 7\n",
      "new folder: 8\n",
      "new folder: 9\n",
      "Confusion Matrix\n",
      "[[161  11   1  45   1   0   0   0   0   0]\n",
      " [143  13   0  48  54   0   0   0   0   0]\n",
      " [ 31   0  65 111   0   6   0   0   0   0]\n",
      " [  1   0   0 409   0   0   0   0   0   0]\n",
      " [ 11   0   1  92   4   0   0   0   0   0]\n",
      " [ 16   0  14  77   0  47   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    evaluate dataset and compute confusion matrix\n",
    "\"\"\"\n",
    "test_folder_path = os.path.join(\n",
    "    diplomka_path,\n",
    "    r'DATA\\DISPLAY_IMAGES\\images_classes_from_camera\\Pricni')\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "test_ds = generate_test_dataset(test_folder_path, image_size=IMG_SIZE)\n",
    "y_true = test_ds.classes  # numpy array of all labels\n",
    "print(y_true)\n",
    "\n",
    "# go trough all folders in the path\n",
    "for fo_number, folder in enumerate(sorted(os.listdir(test_folder_path))):\n",
    "    print(\"new folder:\", folder)\n",
    "    for fi_number, filename in enumerate(os.listdir(test_folder_path+'/'+folder)):\n",
    "        img_path = test_folder_path+'\\\\'+str(folder)+'\\\\'+str(filename)\n",
    "        img = keras.preprocessing.image.load_img(\n",
    "            img_path,\n",
    "            target_size=IMG_SIZE,\n",
    "            color_mode=\"rgb\",\n",
    "            grayscale=False\n",
    "        )\n",
    "\n",
    "        img_array = keras.preprocessing.image.img_to_array(img)\n",
    "        tf_img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "        predictions = model.predict(tf_img_array)\n",
    "        Y_pred = np.around(predictions)  # round prediction\n",
    "        Y_pred = Y_pred.argmax(axis=1)[0]\n",
    "        y_pred.append(Y_pred)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 12899 images belonging to 10 classes.\n",
      "[0 0 0 ... 9 9 9]\n",
      "new folder: 0\n",
      "new folder: 1\n",
      "new folder: 2\n",
      "new folder: 3\n",
      "new folder: 4\n",
      "new folder: 5\n",
      "new folder: 6\n",
      "new folder: 7\n",
      "new folder: 8\n",
      "new folder: 9\n",
      "Confusion Matrix\n",
      "[[1151   26    3    5    0    0    0    0    1    0]\n",
      " [  34 2608    5  136   24    1    1   71    0    0]\n",
      " [  19    5 1991   88    1   25    0    1    0    0]\n",
      " [   5    1    2 2099    0   49    0    3    0    0]\n",
      " [  64   30   22    8 1145    4    0    1    4    4]\n",
      " [  24    0  150   43    5 1403    0    0    0    0]\n",
      " [   0    0    0    0    0    1  705    0    5    0]\n",
      " [  11    0    5   11   35    6    0  392    1    0]\n",
      " [   9    0    0    1    0    0    3    0  198   13]\n",
      " [   3    0    0    1    0   19    0    0    0  218]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    evaluate dataset and compute confusion matrix\n",
    "\"\"\"\n",
    "test_folder_path = os.path.join(\n",
    "    diplomka_path,\n",
    "    r'DATA\\DISPLAY_IMAGES\\images_classes_from_mobile\\10_classes_0_9')\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "test_ds = generate_test_dataset(test_folder_path, image_size=IMG_SIZE)\n",
    "y_true = test_ds.classes  # numpy array of all labels\n",
    "print(y_true)\n",
    "\n",
    "# go trough all folders in the path\n",
    "for fo_number, folder in enumerate(sorted(os.listdir(test_folder_path))):\n",
    "    print(\"new folder:\", folder)\n",
    "    for fi_number, filename in enumerate(os.listdir(test_folder_path+'/'+folder)):\n",
    "        img_path = test_folder_path+'\\\\'+str(folder)+'\\\\'+str(filename)\n",
    "        img = keras.preprocessing.image.load_img(\n",
    "            img_path,\n",
    "            target_size=IMG_SIZE,\n",
    "            color_mode=\"rgb\",\n",
    "            grayscale=False\n",
    "        )\n",
    "\n",
    "        img_array = keras.preprocessing.image.img_to_array(img)\n",
    "        tf_img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "        predictions = model.predict(tf_img_array)\n",
    "        Y_pred = np.around(predictions)  # round prediction\n",
    "        Y_pred = Y_pred.argmax(axis=1)[0]\n",
    "        y_pred.append(Y_pred)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 6191 images belonging to 10 classes.\n",
      "[0 0 0 ... 9 9 9]\n",
      "new folder: 0\n",
      "new folder: 1\n",
      "new folder: 2\n",
      "new folder: 3\n",
      "new folder: 4\n",
      "new folder: 5\n",
      "new folder: 6\n",
      "new folder: 7\n",
      "new folder: 8\n",
      "new folder: 9\n",
      "Confusion Matrix\n",
      "[[ 195    0    0   23    1    0    0    0    0    0]\n",
      " [  25  608    2    1   23    0    1   11    0    0]\n",
      " [   3    5 1387    0    2  123    1    1    0    0]\n",
      " [   4    0    0  561    0    2    0    0    0    0]\n",
      " [   2    0    0    0  613    4    0    0    0    0]\n",
      " [   7    0    1    0    2  776    0    0    0    0]\n",
      " [   3    0    0    1    0   32  834    0    0    0]\n",
      " [  56   60    1    4   20    0    0  584    0    0]\n",
      " [   1    0    0    0    0    0   10    0   86    0]\n",
      " [   9    0    0    0    1   24    9    0   37   35]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    evaluate dataset and compute confusion matrix\n",
    "\"\"\"\n",
    "test_folder_path = os.path.join(\n",
    "    diplomka_path,\n",
    "    r'DATA\\DISPLAY_IMAGES\\images_classes_from_camera\\All_preprocessed')\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "test_ds = generate_test_dataset(test_folder_path, image_size=IMG_SIZE)\n",
    "y_true = test_ds.classes  # numpy array of all labels\n",
    "print(y_true)\n",
    "\n",
    "# go trough all folders in the path\n",
    "for fo_number, folder in enumerate(sorted(os.listdir(test_folder_path))):\n",
    "    print(\"new folder:\", folder)\n",
    "    for fi_number, filename in enumerate(os.listdir(test_folder_path+'/'+folder)):\n",
    "        img_path = test_folder_path+'\\\\'+str(folder)+'\\\\'+str(filename)\n",
    "        img = keras.preprocessing.image.load_img(\n",
    "            img_path,\n",
    "            target_size=IMG_SIZE,\n",
    "            color_mode=\"rgb\",\n",
    "            grayscale=False\n",
    "        )\n",
    "\n",
    "        img_array = keras.preprocessing.image.img_to_array(img)\n",
    "        tf_img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "        predictions = model.predict(tf_img_array)\n",
    "        Y_pred = np.around(predictions)  # round prediction\n",
    "        Y_pred = Y_pred.argmax(axis=1)[0]\n",
    "        y_pred.append(Y_pred)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}